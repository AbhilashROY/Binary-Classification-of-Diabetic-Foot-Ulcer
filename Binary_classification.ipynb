{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of FinalYearProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asP3yxpdpQV"
      },
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow\n",
        "import random\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "import warnings\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LwfnDV3eguR"
      },
      "source": [
        "def load_images_from_folder(folder):\n",
        "\timages = []\n",
        "\tdirs = os.listdir(folder)\n",
        "\n",
        "\tfor filename in dirs:\n",
        "\t\tif os.path.isfile(folder+filename):\n",
        "\t\t\tim = Image.open(folder+filename)\n",
        "\t\t\timResize = im.resize((224,224), Image.ANTIALIAS)\n",
        "\t\t\timResize = np.array(imResize)\n",
        "\t\t\tif imResize is not None:\n",
        "\t\t\t\timages.append(imResize)\n",
        "\treturn images\n",
        "\n",
        "\n",
        "def prepareData(parentPath):\n",
        "\t\n",
        "\t# Make a list of all the 0 label and 1 label images for train, val, and test sets\n",
        "\n",
        "\tall0_path = list()\n",
        "\t\n",
        "\n",
        "\tall1_path = list()\n",
        "\t\n",
        "\n",
        "\tall0_path.append(parentPath+'/0/')\n",
        "\tall1_path.append(parentPath+'/1/')\n",
        "\n",
        "\n",
        "\t# Read images into respective lists\n",
        "\t\n",
        "\n",
        "\tallX = list()\n",
        "\tallY = list()\n",
        "\txTrain = list()\n",
        "\tyTrain = list()\n",
        "\txVal = list()\n",
        "\tyVal = list()\n",
        "\txTest = list()\n",
        "\tyTest = list()\n",
        "\n",
        "\t# Prepare all data for 0 class\n",
        "\tprint('\\n\\n Class 0, reading started..\\n\\n')\n",
        "\t\n",
        "\n",
        "\ttempImgs = list()\n",
        "\ttempImgs = load_images_from_folder(all0_path[0])\n",
        "\tfor i in range(len(tempImgs)):\n",
        "\t\tallX.append(tempImgs[i])\n",
        "\t\tallY.append(0)\n",
        "\n",
        "\t# Prepare all data for 1 class\n",
        "\tprint('\\n\\n Class 1, reading started..\\n\\n')\n",
        "\ttempImgs = list()\n",
        "\ttempImgs = load_images_from_folder(all1_path[0])\n",
        "\tfor i in range(len(tempImgs)):\n",
        "\t\tallX.append(tempImgs[i])\n",
        "\t\tallY.append(1)\n",
        "\n",
        "\txTrain,xTest,yTrain,yTest = train_test_split(allX,allY, test_size=0.20, random_state=23, shuffle = True)\n",
        "\n",
        "\txpTrain,xVal,ypTrain,yVal = train_test_split(xTrain,yTrain, test_size=0.10, random_state=23, shuffle = True)\n",
        "\n",
        "\treturn xpTrain, ypTrain, xVal, yVal, xTest, yTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQJ4-AAE8RJ2"
      },
      "source": [
        "from keras.applications.densenet import DenseNet121\n",
        "def DenseNet121_transfer_actual(input_shape):\n",
        "  res = DenseNet121(weights=None, include_top=False, input_shape=input_shape)\n",
        "  for layers in res.layers:\n",
        "    layers.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(res)\n",
        "  \n",
        "  model.add(Flatten())\n",
        "\n",
        "  ## The following is the vanilla VGG16 architecture's FC layers\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=1000,activation=\"relu\"))\n",
        "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOcg_1NYqJz3"
      },
      "source": [
        "from keras.applications.resnet import ResNet50\n",
        "def ResNet50_transfer_actual(input_shape):\n",
        "  res = ResNet50(weights=None, include_top=False, input_shape=input_shape)\n",
        "  for layers in res.layers:\n",
        "    layers.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(res)\n",
        "  \n",
        "  model.add(Flatten())\n",
        "\n",
        "  ## The following is the vanilla VGG16 architecture's FC layers\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=1000,activation=\"relu\"))\n",
        "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdRx35RP0VjD"
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "def InceptionV3_transfer_actual(input_shape):\n",
        "  res = InceptionV3(weights=None, include_top=False, input_shape=input_shape)\n",
        "  for layers in res.layers:\n",
        "    layers.trainable = True\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(res)\n",
        "  \n",
        "  model.add(Flatten())\n",
        "\n",
        "  ## The following is the vanilla VGG16 architecture's FC layers\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=4096,activation=\"relu\"))\n",
        "  model.add(Dense(units=1000,activation=\"relu\"))\n",
        "  model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWzwMmrHKEry"
      },
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def auroc(y_true, y_pred):\n",
        "  return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0mk9-MC8VRb"
      },
      "source": [
        "parentPath = '/content/drive/My Drive/Colab Notebooks/DFU-Dataset2'\n",
        "xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(parentPath)\n",
        "xTrain = np.array(xTrain)\n",
        "yTrain = np.array(yTrain)\n",
        "xVal = np.array(xVal)\n",
        "yVal = np.array(yVal)\n",
        "xTest = np.array(xTest)\n",
        "yTest = np.array(yTest)\n",
        "\n",
        "# Prepare the data\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "if K.image_data_format() == 'channels_first': \n",
        "  input_shape = (3, img_width, img_height) \n",
        "else:\n",
        "  input_shape = (img_width, img_height, 3) \n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "xTrain = xTrain / 255\n",
        "xVal = xVal / 255\n",
        "xTest = xTest / 255\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gL8BAkLUZJWS"
      },
      "source": [
        "model1 = InceptionV3_transfer_actual(input_shape)\n",
        "#model2 = ResNet50_transfer_actual(input_shape)\n",
        "#model3 = DenseNet121_transfer_actual(input_shape)\n",
        "\n",
        "## Train Model\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200, restore_best_weights=True)\n",
        "model1.fit(xTrain, yTrain, epochs=1000, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "#model2.fit(xTrain, yTrain, epochs=1000, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "#model3.fit(xTrain, yTrain, epochs=1000, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "  \n",
        "model1.save('inception_v3.h5')\n",
        "#model2.save('resnet_50.h5')\n",
        "#model3.save('densenet121.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9l36BtKKHDv"
      },
      "source": [
        "model1 = load_model('inception_v3.h5')\n",
        "testPreds1 = model1.predict_classes(xTest)\n",
        "np.save('testPreds1',testPreds1)\n",
        "print(testPreds1)\n",
        "print(\"done\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jIVdlhEKGyT"
      },
      "source": [
        "model1 = load_model('resnet_50.h5')\n",
        "testPreds2 = model1.predict_classes(xTest)\n",
        "np.save('testPreds2',testPreds2)\n",
        "print(testPreds2)\n",
        "print(\"done\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8ezy-0ZKGco"
      },
      "source": [
        "model1 = load_model('densenet121.h5')\n",
        "testPreds3 = model1.predict_classes(xTest)\n",
        "np.save('testPreds3',testPreds3)\n",
        "print(testPreds3)\n",
        "print(\"done\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEpNC7B05Dpo"
      },
      "source": [
        "'''\n",
        "model1 = load_model('inception_v3.h5')\n",
        "testPreds1 = model1.predict_classes(xTest)\n",
        "print(\"done\\n\")\n",
        "model1 = load_model('resnet_50.h5')\n",
        "testPreds2 = model1.predict_classes(xTest)\n",
        "print(\"done\\n\")\n",
        "model1 = load_model('densenet.h5')\n",
        "testPreds3 = model1.predict_classes(xTest)\n",
        "print(\"done\\n\")\n",
        "'''\n",
        "testPreds1 = np.load('testPreds1.npy')\n",
        "testPreds2 = np.load('testPreds2.npy')\n",
        "testPreds3 = np.load('testPreds3.npy')\n",
        "\n",
        "testPreds = []\n",
        "\n",
        "length = len(testPreds1)\n",
        "print(length)\n",
        "\n",
        "for i in range(length):\n",
        "  total = testPreds1[i] + testPreds2[i] + testPreds3[i]\n",
        "  if(total>1):\n",
        "      testPreds.append(1)\n",
        "  else:\n",
        "      testPreds.append(0)\n",
        "\n",
        "cm = confusion_matrix(yTest, testPreds)\n",
        "cm1 = confusion_matrix(yTest, testPreds1)\n",
        "cm2 = confusion_matrix(yTest, testPreds2)\n",
        "cm3 = confusion_matrix(yTest, testPreds3)\n",
        "\n",
        "sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "precision = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
        "recall = cm[1, 1] / (cm[0, 1] + cm[1, 1])\n",
        "accuracy = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0])\n",
        "\n",
        "sensitivity1 = cm1[0, 0] / (cm1[0, 0] + cm1[0, 1])\n",
        "specificity1 = cm1[1, 1] / (cm1[1, 0] + cm1[1, 1])\n",
        "precision1 = cm1[0, 0] / (cm1[0, 0] + cm1[1, 0])\n",
        "recall1 = cm1[1, 1] / (cm1[0, 1] + cm1[1, 1])\n",
        "accuracy1 = (cm1[0,0] + cm1[1,1]) / (cm1[0,0] + cm1[1,1] + cm1[0,1] + cm1[1,0])\n",
        "\n",
        "sensitivity2 = cm2[0, 0] / (cm2[0, 0] + cm2[0, 1])\n",
        "specificity2 = cm2[1, 1] / (cm2[1, 0] + cm2[1, 1])\n",
        "precision2 = cm2[0, 0] / (cm2[0, 0] + cm2[1, 0])\n",
        "recall2 = cm2[1, 1] / (cm2[0, 1] + cm2[1, 1])\n",
        "accuracy2 = (cm2[0,0] + cm2[1,1]) / (cm2[0,0] + cm2[1,1] + cm2[0,1] + cm2[1,0])\n",
        "\n",
        "sensitivity3 = cm3[0, 0] / (cm3[0, 0] + cm3[0, 1])\n",
        "specificity3 = cm3[1, 1] / (cm3[1, 0] + cm3[1, 1])\n",
        "precision3 = cm3[0, 0] / (cm3[0, 0] + cm3[1, 0])\n",
        "recall3 = cm3[1, 1] / (cm3[0, 1] + cm3[1, 1])\n",
        "accuracy3 = (cm3[0,0] + cm3[1,1]) / (cm3[0,0] + cm3[1,1] + cm3[0,1] + cm3[1,0])\n",
        "\n",
        "print(\"Seed = 5\")\n",
        "print()\n",
        "print(\"For ensemble : \")\n",
        "print()\n",
        "print(\"\\n Accuracy: \",accuracy)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, testPreds))\n",
        "\n",
        "print(\"For Inception : \")\n",
        "print()\n",
        "print(\"\\n Accuracy: \",accuracy1)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity1)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity1)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision1)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall1)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, testPreds1))\n",
        "\n",
        "print(\"For ResNet : \")\n",
        "print()\n",
        "print(\"\\n Accuracy: \",accuracy2)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity2)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity2)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision2)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall2)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, testPreds2))\n",
        "\n",
        "print(\"For DenseNet : \")\n",
        "print()\n",
        "print(\"\\n Accuracy: \",accuracy3)\n",
        "print()\n",
        "print(\"\\n Sensitivity: \",sensitivity3)\n",
        "print()\n",
        "print(\"\\n Specificity: \",specificity3)\n",
        "print()\n",
        "print(\"\\n Precision: \",precision3)\n",
        "print()\n",
        "print(\"\\n Recall: \",recall3)\n",
        "print()\n",
        "print(\"AUC Value: \", roc_auc_score(yTest, testPreds3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6sw6MPOhV6-"
      },
      "source": [
        "\n",
        "def main():\n",
        "\n",
        "  ## First read and organize the data into train-dev-test sets.\n",
        "\n",
        "  parentPath = '/content/drive/My Drive/Colab Notebooks/DFU-Dataset2'\n",
        "\n",
        "  xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(parentPath)\n",
        "\n",
        "  xTrain = np.array(xTrain)\n",
        "  yTrain = np.array(yTrain)\n",
        "  xVal = np.array(xVal)\n",
        "  yVal = np.array(yVal)\n",
        "  xTest = np.array(xTest)\n",
        "  yTest = np.array(yTest)\n",
        "\n",
        "  # Prepare the data\n",
        "  img_width, img_height = 224, 224\n",
        "  \n",
        "  if K.image_data_format() == 'channels_first': \n",
        "    input_shape = (3, img_width, img_height) \n",
        "  else:\n",
        "    input_shape = (img_width, img_height, 3) \n",
        "  \n",
        "  # normalize inputs from 0-255 to 0-1\n",
        "  xTrain = xTrain / 255\n",
        "  xVal = xVal / 255\n",
        "  xTest = xTest / 255\n",
        "\n",
        "  ## Define model\n",
        "\n",
        "  model1 = InceptionV3_transfer_actual(input_shape)\n",
        "  model2 = ResNet50_transfer_actual(input_shape)\n",
        "  model3 = DenseNet121_transfer_actual(input_shape)\n",
        "\n",
        "  ## Train Model\n",
        "  es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=200, restore_best_weights=True)\n",
        "  #model1.fit(xTrain, yTrain, epochs=10, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "  #model2.fit(xTrain, yTrain, epochs=10, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "  #model3.fit(xTrain, yTrain, epochs=10, batch_size=50, validation_data=(xVal, yVal), verbose=1, callbacks = [es])\n",
        "  \n",
        "  #model1.save('inception_v3.h5')\n",
        "  #model2.save('resnet_50.h5')\n",
        "  #model3.save('densenet121.h5')\n",
        "  # to load the saved model: model = load_model('my_model.h5') \n",
        "  ## evaluate model on test data\n",
        "\n",
        "  \n",
        "  model1 = load_model('inception_v3.h5')\n",
        "  testPreds1 = model1.predict_classes(xTest)\n",
        "  print(\"done\\n\")\n",
        "  model1 = load_model('resnet_50.h5')\n",
        "  testPreds2 = model1.predict_classes(xTest)\n",
        "  print(\"done\\n\")\n",
        "  model1 = load_model('densenet121.h5')\n",
        "  testPreds3 = model1.predict_classes(xTest)\n",
        "  print(\"done\\n\")\n",
        "  \n",
        "  testPreds1 = model1.predict_classes(xTest)\n",
        "  print(\"done\\n\")\n",
        "  testPreds2 = model2.predict_classes(xTest)\n",
        "  print(\"done\\n\")\n",
        "  testPreds3 = model3.predict_classes(xTest)\n",
        "  print(\"done\\n\")\n",
        "  \n",
        "\n",
        "  testPreds = []\n",
        "\n",
        "  length = len(testPreds1)\n",
        "  print(length)\n",
        "\n",
        "  for i in range(length):\n",
        "    total = testPreds1[i] + testPreds2[i] + testPreds3[i]\n",
        "    if(total>1):\n",
        "       testPreds.append(1)\n",
        "    else:\n",
        "       testPreds.append(0)\n",
        "\n",
        "  \n",
        "  _, acc = model.evaluate(xTrain, yTrain, verbose=0)\n",
        "  print('Training accuracy> %.3f' % (acc * 100.0))\n",
        "  _, acc = model.evaluate(xVal, yVal, verbose=0)\n",
        "  print('Validation accuracy> %.3f' % (acc * 100.0))\n",
        "  _, acc = model.evaluate(xTest, yTest, verbose=0)\n",
        "  print('Testing accuracy> %.3f' % (acc * 100.0))\n",
        "  testPreds = model.predict_classes(xTest)\n",
        "  \n",
        "  \n",
        "  #print(testPreds);\n",
        "  cm = confusion_matrix(yTest, testPreds)\n",
        "  sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "  specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "  precision = cm[0, 0] / (cm[0, 0] + cm[1, 0])\n",
        "  recall = cm[1, 1] / (cm[0, 1] + cm[1, 1])\n",
        "  accuracy = (cm[0,0] + cm[1,1]) / (cm[0,0] + cm[1,1] + cm[0,1] + cm[1,0])\n",
        "\n",
        "  print(\"\\n Accuracy: \",accuracy)\n",
        "  print()\n",
        "  print(\"\\n Sensitivity: \",sensitivity)\n",
        "  print()\n",
        "  print(\"\\n Specificity: \",specificity)\n",
        "  print()\n",
        "  print(\"\\n Precision: \",precision)\n",
        "  print()\n",
        "  print(\"\\n Recall: \",recall)\n",
        "  print()\n",
        "  print(\"AUC Value: \", roc_auc_score(yTest, testPreds))\n",
        "\n",
        "  ## Visualize Results\n",
        "\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-hY7YoXGs_v"
      },
      "source": [
        "import statistics\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred = testPreds\n",
        "label = yTest[:]\n",
        "fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
        "auc = metrics.roc_auc_score(label, pred)\n",
        "plt.plot(fpr,tpr,label=\"Ensemble, auc=\"+str(auc))\n",
        "\n",
        "pred = testPreds1\n",
        "label = yTest[:]\n",
        "fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
        "auc = metrics.roc_auc_score(label, pred)\n",
        "plt.plot(fpr,tpr,label=\"InceptionV3, auc=\"+str(auc))\n",
        "\n",
        "pred = testPreds2\n",
        "label = yTest[:]\n",
        "fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
        "auc = metrics.roc_auc_score(label, pred)\n",
        "plt.plot(fpr,tpr,label=\"ResNet50, auc=\"+str(auc))\n",
        "\n",
        "pred = testPreds3\n",
        "label = yTest[:]\n",
        "fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
        "auc = metrics.roc_auc_score(label, pred)\n",
        "plt.plot(fpr,tpr,label=\"DenseNet121, auc=\"+str(auc))\n",
        "\n",
        "plt.title('ROC Curve: DFU v/s No DFU', fontsize = 12)\n",
        "plt.xlabel('False Positive Rate', fontsize=12)\n",
        "plt.ylabel('True Positive Rate', fontsize=12)\n",
        "plt.legend(loc=0)\n",
        "#plt.show()\n",
        "plt.savefig('ROC_DFU.eps', format = 'eps')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}